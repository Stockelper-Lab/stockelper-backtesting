#!/usr/bin/env python
"""
DART ê³µì‹œì •ë³´ ì§€í‘œ ì¶”ì¶œ CLI

ê³µì‹œì •ë³´ í…Œì´ë¸”ì—ì„œ ì§€í‘œë¥¼ ì¶”ì¶œí•˜ì—¬ PostgreSQLì— ì ì¬í•˜ëŠ” CLI ë„êµ¬ì…ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    uv run python dart_indicator_cli.py --help
    uv run python dart_indicator_cli.py extract          # ì§€í‘œ ì¶”ì¶œ ë° DB ì ì¬
    uv run python dart_indicator_cli.py list-tables      # í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ
    uv run python dart_indicator_cli.py preview          # ë¯¸ë¦¬ë³´ê¸° (ì ì¬í•˜ì§€ ì•ŠìŒ)
"""

import argparse
import json
import warnings
from typing import Optional

import pandas as pd

from db_con import (
    DB_CONFIG,
    get_connection,
    get_sqlalchemy_engine,
    get_table_data,
    get_table_list,
)

warnings.filterwarnings('ignore')


# ê³µì‹œì •ë³´ í…Œì´ë¸” ëª©ë¡
DART_TABLES = [
    'dart_bdwt_is_decsn',
    'dart_bsn_inh_decsn',
    'dart_bsn_trf_decsn',
    'dart_cmp_dv_decsn',
    'dart_cmp_dvmg_decsn',
    'dart_cmp_mg_decsn',
    'dart_cr_decsn',
    'dart_cvbd_is_decsn',
    'dart_fric_decsn',
    'dart_otcpr_stk_invscr_inh_decsn',
    'dart_otcpr_stk_invscr_trf_decsn',
    'dart_pifric_decsn',
    'dart_piic_decsn',
    'dart_stk_extr_decsn',
    'dart_tgast_inh_decsn',
    'dart_tgast_trf_decsn',
    'dart_tsstk_aq_decsn',
    'dart_tsstk_aq_trctr_cc_decsn',
    'dart_tsstk_aq_trctr_cns_decsn',
    'dart_tsstk_dp_decsn',
]

# report_type ë§¤í•‘
REPORT_TYPE_MAPPING = {
    'bdwtIsDecsn': 'ì‹ ì£¼ì¸ìˆ˜ê¶Œë¶€ì‚¬ì±„ë°œí–‰',
    'bsnInhDecsn': 'ì˜ì—…ì–‘ìˆ˜ ê²°ì •',
    'bsnTrfDecsn': 'ì˜ì—…ì–‘ë„ ê²°ì •',
    'cmpDvDecsn': 'íšŒì‚¬ë¶„í•  ê²°ì •',
    'cmpDvmgDecsn': 'íšŒì‚¬ë¶„í• í•©ë³‘ ê²°ì •',
    'cmpMgDecsn': 'íšŒì‚¬í•©ë³‘ ê²°ì •',
    'crDecsn': 'ê°ì ê²°ì •',
    'cvbdIsDecsn': 'ì „í™˜ì‚¬ì±„ê¶Œ ë°œí–‰ê²°ì •',
    'fricDecsn': 'ë¬´ìƒì¦ì ê²°ì •',
    'otcprStkInvscrInhDecsn': 'íƒ€ë²•ì¸ ì£¼ì‹ ë° ì¶œìì¦ê¶Œ ì–‘ìˆ˜ê²°ì •',
    'otcprStkInvscrTrfDecsn': 'íƒ€ë²•ì¸ ì£¼ì‹ ë° ì¶œìì¦ê¶Œ ì–‘ë„ê²°ì •',
    'pifricDecsn': 'ìœ ë¬´ìƒì¦ì ê²°ì •',
    'piicDecsn': 'ìœ ìƒì¦ì ê²°ì •',
    'stkExtrDecsn': 'ì£¼ì‹êµí™˜Â·ì´ì „ ê²°ì •',
    'tgastInhDecsn': 'ìœ í˜•ìì‚° ì–‘ìˆ˜ ê²°ì •',
    'tgastTrfDecsn': 'ìœ í˜•ìì‚° ì–‘ë„ ê²°ì •',
    'tsstkAqDecsn': 'ìê¸°ì£¼ì‹ ì·¨ë“ ê²°ì •',
    'tsstkAqTrctrCcDecsn': 'ìê¸°ì£¼ì‹ì·¨ë“ ì‹ íƒê³„ì•½ í•´ì§€ ê²°ì •',
    'tsstkAqTrctrCnsDecsn': 'ìê¸°ì£¼ì‹ì·¨ë“ ì‹ íƒê³„ì•½ ì²´ê²° ê²°ì •',
    'tsstkDpDecsn': 'ìê¸°ì£¼ì‹ ì²˜ë¶„ ê²°ì •',
}

# ì¶”ì¶œí•  ì§€í‘œ ëª©ë¡
INDICATOR_NAMES = [
    'í¬ì„ë¥ ',
    'ë¬´ìƒì¦ì ë°°ì •ë¹„ìœ¨',
    'ê°ìë¹„ìœ¨',
    'ìë³¸ê¸ˆ ê°ì†Œìœ¨',
    'ì „í™˜í¬ì„ë¥ ',
    'BW í¬ì„ë¥ ',
    'í•©ë³‘ë¹„ìœ¨',
    'ë¶„í• ë¹„ìœ¨',
    'ë¶„í• í•©ë³‘ë¹„ìœ¨',
    'êµí™˜ì´ì „ë¹„ìœ¨',
]


def json_text_to_dataframe(df: pd.DataFrame, column_name: str) -> pd.DataFrame:
    """
    DataFrameì˜ JSON í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì„ íŒŒì‹±í•˜ì—¬ ìƒˆë¡œìš´ DataFrameìœ¼ë¡œ ë°˜í™˜
    
    Args:
        df: ì›ë³¸ DataFrame
        column_name: JSONì´ í¬í•¨ëœ ì»¬ëŸ¼ëª…
        
    Returns:
        JSON íŒŒì‹± ê²°ê³¼ DataFrame
    """
    result_rows = []
    
    for idx, row in df.iterrows():
        payload = row[column_name]
        if payload is None:
            result_rows.append({})
            continue
            
        try:
            if isinstance(payload, str):
                parsed = json.loads(payload)
            elif isinstance(payload, dict):
                parsed = payload
            else:
                result_rows.append({})
                continue
            result_rows.append(parsed)
        except (json.JSONDecodeError, TypeError):
            result_rows.append({})
    
    return pd.DataFrame(result_rows)


def erase_comma_to_float(num_str) -> Optional[float]:
    """ì½¤ë§ˆê°€ í¬í•¨ëœ ìˆ«ì ë¬¸ìì—´ì„ floatë¡œ ë³€í™˜"""
    try:
        if num_str is None:
            return None
        return float(str(num_str).replace(',', ''))
    except (ValueError, AttributeError):
        return None


def cal_indicators(indicator_name: str, df: pd.DataFrame) -> pd.DataFrame:
    """
    ì§€í‘œëª…ì— ë”°ë¼ í•´ë‹¹ ì§€í‘œë¥¼ ê³„ì‚°í•˜ì—¬ ë°˜í™˜
    
    Args:
        indicator_name: ì§€í‘œëª…
        df: ì „ì²´ ê³µì‹œì •ë³´ DataFrame
        
    Returns:
        ì§€í‘œê°€ ê³„ì‚°ëœ DataFrame
    """
    tar_df = pd.DataFrame()
    trimmed_df = pd.DataFrame()
    
    if indicator_name == 'í¬ì„ë¥ ':
        tar_df = df.loc[df['report_type'] == 'ìœ ìƒì¦ì ê²°ì •', :].copy()
        if len(tar_df) == 0:
            return pd.DataFrame()
        trimmed_df = json_text_to_dataframe(tar_df, 'payload')
        if 'nstk_ostk_cnt' in trimmed_df.columns and 'bfic_tisstk_ostk' in trimmed_df.columns:
            trimmed_df['nstk_ostk_cnt'] = trimmed_df['nstk_ostk_cnt'].apply(erase_comma_to_float)
            trimmed_df['bfic_tisstk_ostk'] = trimmed_df['bfic_tisstk_ostk'].apply(erase_comma_to_float)
            trimmed_df['idc_score'] = trimmed_df['nstk_ostk_cnt'] / trimmed_df['bfic_tisstk_ostk']
        else:
            trimmed_df['idc_score'] = None
            
    elif indicator_name == 'ë¬´ìƒì¦ì ë°°ì •ë¹„ìœ¨':
        tar_df = df.loc[df['report_type'] == 'ë¬´ìƒì¦ì ê²°ì •', :].copy()
        if len(tar_df) == 0:
            return pd.DataFrame()
        trimmed_df = json_text_to_dataframe(tar_df, 'payload')
        if 'nstk_ascnt_ps_ostk' in trimmed_df.columns:
            trimmed_df['nstk_ascnt_ps_ostk'] = trimmed_df['nstk_ascnt_ps_ostk'].apply(erase_comma_to_float)
            trimmed_df['idc_score'] = trimmed_df['nstk_ascnt_ps_ostk']
        else:
            trimmed_df['idc_score'] = None
            
    elif indicator_name == 'ê°ìë¹„ìœ¨':
        tar_df = df.loc[df['report_type'] == 'ê°ì ê²°ì •', :].copy()
        if len(tar_df) == 0:
            return pd.DataFrame()
        trimmed_df = json_text_to_dataframe(tar_df, 'payload')
        if 'cr_rt_ostk' in trimmed_df.columns:
            trimmed_df['cr_rt_ostk'] = trimmed_df['cr_rt_ostk'].apply(erase_comma_to_float)
            trimmed_df['idc_score'] = trimmed_df['cr_rt_ostk']
        else:
            trimmed_df['idc_score'] = None
            
    elif indicator_name == 'ìë³¸ê¸ˆ ê°ì†Œìœ¨':
        tar_df = df.loc[df['report_type'] == 'ê°ì ê²°ì •', :].copy()
        if len(tar_df) == 0:
            return pd.DataFrame()
        trimmed_df = json_text_to_dataframe(tar_df, 'payload')
        if 'bfcr_cpt' in trimmed_df.columns and 'atcr_cpt' in trimmed_df.columns:
            trimmed_df['bfcr_cpt'] = trimmed_df['bfcr_cpt'].apply(erase_comma_to_float)
            trimmed_df['atcr_cpt'] = trimmed_df['atcr_cpt'].apply(erase_comma_to_float)
            trimmed_df['idc_score'] = (trimmed_df['bfcr_cpt'] - trimmed_df['atcr_cpt']) / trimmed_df['bfcr_cpt']
        else:
            trimmed_df['idc_score'] = None
            
    elif indicator_name == 'ì „í™˜í¬ì„ë¥ ':
        tar_df = df.loc[df['report_type'] == 'ì „í™˜ì‚¬ì±„ê¶Œ ë°œí–‰ê²°ì •', :].copy()
        if len(tar_df) == 0:
            return pd.DataFrame()
        trimmed_df = json_text_to_dataframe(tar_df, 'payload')
        if 'cvisstk_tisstk_vs' in trimmed_df.columns:
            trimmed_df['cvisstk_tisstk_vs'] = trimmed_df['cvisstk_tisstk_vs'].apply(erase_comma_to_float)
            trimmed_df['idc_score'] = trimmed_df['cvisstk_tisstk_vs']
        else:
            trimmed_df['idc_score'] = None
            
    elif indicator_name == 'BW í¬ì„ë¥ ':
        tar_df = df.loc[df['report_type'] == 'ì‹ ì£¼ì¸ìˆ˜ê¶Œë¶€ì‚¬ì±„ë°œí–‰', :].copy()
        if len(tar_df) == 0:
            return pd.DataFrame()
        trimmed_df = json_text_to_dataframe(tar_df, 'payload')
        if 'nstk_isstk_tisstk_vs' in trimmed_df.columns:
            trimmed_df['nstk_isstk_tisstk_vs'] = trimmed_df['nstk_isstk_tisstk_vs'].apply(erase_comma_to_float)
            trimmed_df['idc_score'] = trimmed_df['nstk_isstk_tisstk_vs']
        else:
            trimmed_df['idc_score'] = None
            
    elif indicator_name == 'í•©ë³‘ë¹„ìœ¨':
        tar_df = df.loc[df['report_type'] == 'íšŒì‚¬í•©ë³‘ ê²°ì •', :].copy()
        if len(tar_df) == 0:
            return pd.DataFrame()
        trimmed_df = json_text_to_dataframe(tar_df, 'payload')
        if 'mg_rt' in trimmed_df.columns:
            trimmed_df['mg_rt'] = trimmed_df['mg_rt'].apply(erase_comma_to_float)
            trimmed_df['idc_score'] = trimmed_df['mg_rt']
        else:
            trimmed_df['idc_score'] = None
            
    elif indicator_name == 'ë¶„í• ë¹„ìœ¨':
        tar_df = df.loc[df['report_type'] == 'íšŒì‚¬ë¶„í•  ê²°ì •', :].copy()
        if len(tar_df) == 0:
            return pd.DataFrame()
        trimmed_df = json_text_to_dataframe(tar_df, 'payload')
        if 'dv_rt' in trimmed_df.columns:
            trimmed_df['dv_rt'] = trimmed_df['dv_rt'].apply(erase_comma_to_float)
            trimmed_df['idc_score'] = trimmed_df['dv_rt']
        else:
            trimmed_df['idc_score'] = None
            
    elif indicator_name == 'ë¶„í• í•©ë³‘ë¹„ìœ¨':
        tar_df = df.loc[df['report_type'] == 'íšŒì‚¬ë¶„í• í•©ë³‘ ê²°ì •', :].copy()
        if len(tar_df) == 0:
            return pd.DataFrame()
        trimmed_df = json_text_to_dataframe(tar_df, 'payload')
        if 'dvmg_rt' in trimmed_df.columns:
            trimmed_df['dvmg_rt'] = trimmed_df['dvmg_rt'].apply(erase_comma_to_float)
            trimmed_df['idc_score'] = trimmed_df['dvmg_rt']
        else:
            trimmed_df['idc_score'] = None
            
    elif indicator_name == 'êµí™˜ì´ì „ë¹„ìœ¨':
        tar_df = df.loc[df['report_type'] == 'ì£¼ì‹êµí™˜Â·ì´ì „ ê²°ì •', :].copy()
        if len(tar_df) == 0:
            return pd.DataFrame()
        trimmed_df = json_text_to_dataframe(tar_df, 'payload')
        if 'extr_rt' in trimmed_df.columns:
            trimmed_df['extr_rt'] = trimmed_df['extr_rt'].apply(erase_comma_to_float)
            trimmed_df['idc_score'] = trimmed_df['extr_rt']
        else:
            trimmed_df['idc_score'] = None
    else:
        return pd.DataFrame()
    
    if len(tar_df) == 0:
        return pd.DataFrame()
        
    tar_df = tar_df.reset_index(drop=True)
    tar_df['idc_nm'] = indicator_name
    
    if 'idc_score' in trimmed_df.columns:
        tar_df['idc_score'] = trimmed_df['idc_score'].values
    else:
        tar_df['idc_score'] = None
        
    return tar_df


def load_all_dart_tables(conn, limit: Optional[int] = None, verbose: bool = True) -> pd.DataFrame:
    """
    ëª¨ë“  DART ê³µì‹œì •ë³´ í…Œì´ë¸”ì„ ë¡œë“œí•˜ê³  ë³‘í•©
    
    Args:
        conn: DB ì—°ê²° ê°ì²´
        limit: í…Œì´ë¸”ë‹¹ ì¡°íšŒí•  í–‰ ìˆ˜ (Noneì´ë©´ ì „ì²´)
        verbose: ì§„í–‰ìƒí™© ì¶œë ¥ ì—¬ë¶€
        
    Returns:
        ë³‘í•©ëœ ì „ì²´ DataFrame
    """
    total_tables = pd.DataFrame()
    
    for table_nm in DART_TABLES:
        if verbose:
            print(f"ğŸ“¥ í…Œì´ë¸” ë¡œë“œ ì¤‘: {table_nm}")
        
        try:
            tar_table = get_table_data(conn, table_nm, limit=limit)
            if tar_table is not None and len(tar_table) > 0:
                total_tables = pd.concat([total_tables, tar_table], axis=0, ignore_index=True)
                if verbose:
                    print(f"   âœ… {len(tar_table)}ê°œ í–‰ ë¡œë“œë¨")
            else:
                if verbose:
                    print(f"   âš ï¸ ë°ì´í„° ì—†ìŒ")
        except Exception as e:
            if verbose:
                print(f"   âŒ ì˜¤ë¥˜: {e}")
    
    # report_type ë§¤í•‘ ì ìš©
    if 'report_type' in total_tables.columns:
        total_tables['report_type'] = total_tables['report_type'].map(REPORT_TYPE_MAPPING)
    
    return total_tables


def extract_all_indicators(total_tables: pd.DataFrame, verbose: bool = True) -> pd.DataFrame:
    """
    ì „ì²´ ë°ì´í„°ì—ì„œ ëª¨ë“  ì§€í‘œ ì¶”ì¶œ
    
    Args:
        total_tables: ì „ì²´ ê³µì‹œì •ë³´ DataFrame
        verbose: ì§„í–‰ìƒí™© ì¶œë ¥ ì—¬ë¶€
        
    Returns:
        ëª¨ë“  ì§€í‘œê°€ ì¶”ì¶œëœ DataFrame
    """
    result_df = pd.DataFrame()
    
    for indicator_name in INDICATOR_NAMES:
        if verbose:
            print(f"ğŸ“Š ì§€í‘œ ì¶”ì¶œ ì¤‘: {indicator_name}")
        
        try:
            temp_df = cal_indicators(indicator_name, total_tables)
            if len(temp_df) > 0:
                result_df = pd.concat([result_df, temp_df], axis=0, ignore_index=True)
                if verbose:
                    print(f"   âœ… {len(temp_df)}ê°œ í–‰ ì¶”ì¶œë¨")
            else:
                if verbose:
                    print(f"   âš ï¸ í•´ë‹¹ ë°ì´í„° ì—†ìŒ")
        except Exception as e:
            if verbose:
                print(f"   âŒ ì˜¤ë¥˜: {e}")
    
    # idc_scoreê°€ ì—†ëŠ” í–‰ ì œê±°
    if 'idc_score' in result_df.columns:
        result_df = result_df.dropna(subset=['idc_score'])
    
    return result_df


def upload_to_db(
    df: pd.DataFrame, 
    table_name: str = 'score_table_dart_idc',
    schema: str = 'public',
    if_exists: str = 'replace',
    verbose: bool = True
) -> bool:
    """
    DataFrameì„ PostgreSQLì— ì—…ë¡œë“œ
    
    Args:
        df: ì—…ë¡œë“œí•  DataFrame
        table_name: í…Œì´ë¸” ì´ë¦„
        schema: ìŠ¤í‚¤ë§ˆ ì´ë¦„
        if_exists: 'replace', 'append', 'fail' ì¤‘ ì„ íƒ
        verbose: ì§„í–‰ìƒí™© ì¶œë ¥ ì—¬ë¶€
        
    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    try:
        engine = get_sqlalchemy_engine()
        
        # payload ì»¬ëŸ¼ ì œì™¸ (dict íƒ€ì…ì€ ì§ì ‘ ì €ì¥ ë¶ˆê°€)
        upload_df = df.drop(columns=['payload'], errors='ignore')
        
        if verbose:
            print(f"\nğŸ“¤ DB ì—…ë¡œë“œ ì¤‘: {schema}.{table_name}")
            print(f"   í–‰ ìˆ˜: {len(upload_df)}")
            print(f"   ì»¬ëŸ¼: {list(upload_df.columns)}")
        
        upload_df.to_sql(
            name=table_name,
            con=engine,
            schema=schema,
            if_exists=if_exists,
            index=False
        )
        
        if verbose:
            print(f"   âœ… ì—…ë¡œë“œ ì™„ë£Œ!")
        
        return True
        
    except Exception as e:
        if verbose:
            print(f"   âŒ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False


def cmd_list_tables(args):
    """í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ ëª…ë ¹"""
    print("ğŸ” DB ì—°ê²° ì¤‘...")
    conn = get_connection()
    
    if not conn:
        print("âŒ DB ì—°ê²° ì‹¤íŒ¨")
        return
    
    try:
        tables = get_table_list(conn)
        
        if args.dart_only:
            # DART í…Œì´ë¸”ë§Œ í•„í„°ë§
            dart_tables = tables[tables['table_name'].str.startswith('dart_')]
            print(f"\nğŸ“‹ DART ê³µì‹œì •ë³´ í…Œì´ë¸” ({len(dart_tables)}ê°œ):")
            for _, row in dart_tables.iterrows():
                print(f"   - {row['table_schema']}.{row['table_name']}")
        else:
            print(f"\nğŸ“‹ ì „ì²´ í…Œì´ë¸” ëª©ë¡ ({len(tables)}ê°œ):")
            for _, row in tables.iterrows():
                print(f"   - {row['table_schema']}.{row['table_name']}")
    finally:
        conn.close()
        print("\nğŸ”’ DB ì—°ê²° ì¢…ë£Œ")


def cmd_preview(args):
    """ë¯¸ë¦¬ë³´ê¸° ëª…ë ¹ (DB ì ì¬í•˜ì§€ ì•ŠìŒ)"""
    print("ğŸ” DB ì—°ê²° ì¤‘...")
    conn = get_connection()
    
    if not conn:
        print("âŒ DB ì—°ê²° ì‹¤íŒ¨")
        return
    
    try:
        # ë°ì´í„° ë¡œë“œ
        print("\nğŸ“¥ ê³µì‹œì •ë³´ í…Œì´ë¸” ë¡œë“œ ì¤‘...")
        total_tables = load_all_dart_tables(conn, limit=args.limit)
        print(f"\nâœ… ì´ {len(total_tables)}ê°œ í–‰ ë¡œë“œë¨")
        
        if len(total_tables) == 0:
            print("âš ï¸ ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ì§€í‘œ ì¶”ì¶œ
        print("\nğŸ“Š ì§€í‘œ ì¶”ì¶œ ì¤‘...")
        result_df = extract_all_indicators(total_tables)
        print(f"\nâœ… ì´ {len(result_df)}ê°œ ì§€í‘œ ì¶”ì¶œë¨")
        
        # ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
        if len(result_df) > 0:
            print("\nğŸ“‹ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°:")
            print(result_df[['idc_nm', 'idc_score', 'report_type']].head(20).to_string())
            
            print("\nğŸ“Š ì§€í‘œë³„ í†µê³„:")
            stats = result_df.groupby('idc_nm')['idc_score'].agg(['count', 'mean', 'min', 'max'])
            print(stats.to_string())
            
    finally:
        conn.close()
        print("\nğŸ”’ DB ì—°ê²° ì¢…ë£Œ")


def cmd_extract(args):
    """ì§€í‘œ ì¶”ì¶œ ë° DB ì ì¬ ëª…ë ¹"""
    print("ğŸ” DB ì—°ê²° ì¤‘...")
    conn = get_connection()
    
    if not conn:
        print("âŒ DB ì—°ê²° ì‹¤íŒ¨")
        return
    
    try:
        # ë°ì´í„° ë¡œë“œ
        print("\nğŸ“¥ ê³µì‹œì •ë³´ í…Œì´ë¸” ë¡œë“œ ì¤‘...")
        total_tables = load_all_dart_tables(conn, limit=args.limit)
        print(f"\nâœ… ì´ {len(total_tables)}ê°œ í–‰ ë¡œë“œë¨")
        
        if len(total_tables) == 0:
            print("âš ï¸ ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ì§€í‘œ ì¶”ì¶œ
        print("\nğŸ“Š ì§€í‘œ ì¶”ì¶œ ì¤‘...")
        result_df = extract_all_indicators(total_tables)
        print(f"\nâœ… ì´ {len(result_df)}ê°œ ì§€í‘œ ì¶”ì¶œë¨")
        
        if len(result_df) == 0:
            print("âš ï¸ ì¶”ì¶œëœ ì§€í‘œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # DB ì ì¬
        success = upload_to_db(
            result_df,
            table_name=args.table_name,
            schema=args.schema,
            if_exists=args.if_exists
        )
        
        if success:
            print(f"\nğŸ‰ ì‘ì—… ì™„ë£Œ! {args.schema}.{args.table_name} í…Œì´ë¸”ì— {len(result_df)}ê°œ í–‰ì´ ì ì¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print("\nâŒ DB ì ì¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            
    finally:
        conn.close()
        print("\nğŸ”’ DB ì—°ê²° ì¢…ë£Œ")


def main():
    """ë©”ì¸ CLI ì§„ì…ì """
    parser = argparse.ArgumentParser(
        description='DART ê³µì‹œì •ë³´ ì§€í‘œ ì¶”ì¶œ CLI',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  python dart_indicator_cli.py list-tables              # í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ
  python dart_indicator_cli.py list-tables --dart-only  # DART í…Œì´ë¸”ë§Œ ì¡°íšŒ
  python dart_indicator_cli.py preview --limit 100      # ë¯¸ë¦¬ë³´ê¸° (100ê°œì”©)
  python dart_indicator_cli.py extract                  # ì „ì²´ ì¶”ì¶œ ë° DB ì ì¬
  python dart_indicator_cli.py extract --if-exists append  # ê¸°ì¡´ ë°ì´í„°ì— ì¶”ê°€
        """
    )
    
    subparsers = parser.add_subparsers(dest='command', help='ëª…ë ¹ì–´')
    
    # list-tables ëª…ë ¹
    list_parser = subparsers.add_parser('list-tables', help='í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ')
    list_parser.add_argument(
        '--dart-only', 
        action='store_true', 
        help='DART ê³µì‹œì •ë³´ í…Œì´ë¸”ë§Œ í‘œì‹œ'
    )
    list_parser.set_defaults(func=cmd_list_tables)
    
    # preview ëª…ë ¹
    preview_parser = subparsers.add_parser('preview', help='ì§€í‘œ ì¶”ì¶œ ë¯¸ë¦¬ë³´ê¸° (DB ì ì¬í•˜ì§€ ì•ŠìŒ)')
    preview_parser.add_argument(
        '--limit', 
        type=int, 
        default=100, 
        help='í…Œì´ë¸”ë‹¹ ì¡°íšŒí•  í–‰ ìˆ˜ (ê¸°ë³¸ê°’: 100)'
    )
    preview_parser.set_defaults(func=cmd_preview)
    
    # extract ëª…ë ¹
    extract_parser = subparsers.add_parser('extract', help='ì§€í‘œ ì¶”ì¶œ ë° DB ì ì¬')
    extract_parser.add_argument(
        '--limit', 
        type=int, 
        default=None, 
        help='í…Œì´ë¸”ë‹¹ ì¡°íšŒí•  í–‰ ìˆ˜ (ê¸°ë³¸ê°’: ì „ì²´)'
    )
    extract_parser.add_argument(
        '--table-name', 
        type=str, 
        default='score_table_dart_idc', 
        help='ì €ì¥í•  í…Œì´ë¸” ì´ë¦„ (ê¸°ë³¸ê°’: score_table_dart_idc)'
    )
    extract_parser.add_argument(
        '--schema', 
        type=str, 
        default='public', 
        help='ì €ì¥í•  ìŠ¤í‚¤ë§ˆ (ê¸°ë³¸ê°’: public)'
    )
    extract_parser.add_argument(
        '--if-exists', 
        type=str, 
        choices=['replace', 'append', 'fail'], 
        default='replace', 
        help='í…Œì´ë¸”ì´ ì¡´ì¬í•  ê²½ìš° ë™ì‘ (ê¸°ë³¸ê°’: replace)'
    )
    extract_parser.set_defaults(func=cmd_extract)
    
    args = parser.parse_args()
    
    if args.command is None:
        parser.print_help()
        return
    
    args.func(args)


if __name__ == '__main__':
    main()
